var documenterSearchIndex = {"docs":
[{"location":"api/functional/","page":"Functional","title":"Functional","text":"CurrentModule = Lux","category":"page"},{"location":"api/functional/#Functional-Layers","page":"Functional","title":"Functional Layers","text":"","category":"section"},{"location":"api/functional/","page":"Functional","title":"Functional","text":"note: Note\nThese functions expose the backend of Lux.jl. In the long-term we plan to move these into NNlib","category":"page"},{"location":"api/functional/","page":"Functional","title":"Functional","text":"Lux.dropout\nLux.normalization","category":"page"},{"location":"api/functional/#Lux.dropout","page":"Functional","title":"Lux.dropout","text":"dropout(rng::AbstractRNG, x, prob, dims, ::Val{training})\ndropout(rng::AbstractRNG, x, mask, prob, dims, t::Val{training}, ::Val{update_mask})\n\nIf training then dropout is applied on x with probability prob along dims. If mask is passed it is used if update_mask is false. If update_mask is true then the mask is generated and used.\n\n\n\n\n\n","category":"function"},{"location":"api/functional/#Lux.normalization","page":"Functional","title":"Lux.normalization","text":"normalization(x, running_mean, running_var, scale, bias, activation, reduce_dims, ::Val{training}, momentum, epsilon)\n\nPerforms BatchNorm/GroupNorm/InstanceNorm based on input configuration\n\nnote: Note\nDetailed docs are WIP\n\n\n\n\n\n","category":"function"},{"location":"introduction/ecosystem/#Extended-Deep-Learning-Ecosystem","page":"Ecosystem","title":"Extended Deep Learning Ecosystem","text":"","category":"section"},{"location":"introduction/ecosystem/","page":"Ecosystem","title":"Ecosystem","text":"As you might have noticed we don't do much apart from Neural Networks. All other parts of the DL training/evaluation pipeline should be offloaded to:","category":"page"},{"location":"introduction/ecosystem/","page":"Ecosystem","title":"Ecosystem","text":"Data Manipulation/Loading – Augmentor.jl, DataLoaders.jl, Images.jl, DataAugmentation.jl\nOptimisation – Optimisers.jl, ParameterSchedulers.jl\nAutomatic Differentiation – Zygote.jl\nParameter Manipulation – Functors.jl\nModel Checkpointing – Serialization.jl\nActivation Functions / Common Neural Network Primitives – NNlib.jl\nDistributed DataParallel Training – FluxMPI.jl\nTraining Visualization – Wandb.jl, TensorBoardLogger.jl","category":"page"},{"location":"api/core/","page":"Core","title":"Core","text":"CurrentModule = Lux","category":"page"},{"location":"api/core/#General","page":"Core","title":"General","text":"","category":"section"},{"location":"api/core/","page":"Core","title":"Core","text":"Lux.apply\nLux.setup","category":"page"},{"location":"api/core/#Lux.apply","page":"Core","title":"Lux.apply","text":"apply(model::AbstractExplicitLayer, x, ps::Union{ComponentArray,NamedTuple}, st::NamedTuple)\n\nSimply calls model(x, ps, st)\n\n\n\n\n\n","category":"function"},{"location":"api/core/#Lux.setup","page":"Core","title":"Lux.setup","text":"setup(rng::AbstractRNG, l::AbstractExplicitLayer)\n\nShorthand for getting the parameters and states of the layer l. Is equivalent to (initialparameters(rng, l), initialstates(rng, l)).\n\n\n\n\n\n","category":"function"},{"location":"api/core/#Parameters","page":"Core","title":"Parameters","text":"","category":"section"},{"location":"api/core/","page":"Core","title":"Core","text":"Lux.initialparameters\nLux.parameterlength","category":"page"},{"location":"api/core/#Lux.initialparameters","page":"Core","title":"Lux.initialparameters","text":"initialparameters(rng::AbstractRNG, l)\n\nGenerate the initial parameters of the layer l.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#Lux.parameterlength","page":"Core","title":"Lux.parameterlength","text":"parameterlength(l)\n\nReturn the total number of parameters of the layer l.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#States","page":"Core","title":"States","text":"","category":"section"},{"location":"api/core/","page":"Core","title":"Core","text":"Lux.initialstates\nLux.statelength\nLux.testmode\nLux.trainmode\nLux.update_state","category":"page"},{"location":"api/core/#Lux.initialstates","page":"Core","title":"Lux.initialstates","text":"initialstates(rng::AbstractRNG, l)\n\nGenerate the initial states of the layer l.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#Lux.statelength","page":"Core","title":"Lux.statelength","text":"statelength(l)\n\nReturn the total number of states of the layer l.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#Lux.testmode","page":"Core","title":"Lux.testmode","text":"testmode(st::NamedTuple, mode::Bool=true)\n\nMake all occurances of training in state st !mode\n\n\n\n\n\n","category":"function"},{"location":"api/core/#Lux.trainmode","page":"Core","title":"Lux.trainmode","text":"trainmode(x::Any, mode::Bool=true)\n\nMake all occurances of training in state st mode\n\n\n\n\n\n","category":"function"},{"location":"api/core/#Lux.update_state","page":"Core","title":"Lux.update_state","text":"update_state(st::NamedTuple, key::Symbol, value; layer_check=_default_layer_check(key))\n\nRecursively update all occurances of the key in the state st with the value.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#Index","page":"Core","title":"Index","text":"","category":"section"},{"location":"api/core/","page":"Core","title":"Core","text":"Pages = [\"core.md\"]","category":"page"},{"location":"api/utilities/","page":"Utilities","title":"Utilities","text":"CurrentModule = Lux","category":"page"},{"location":"api/utilities/#Data-Transfer","page":"Utilities","title":"Data Transfer","text":"","category":"section"},{"location":"api/utilities/","page":"Utilities","title":"Utilities","text":"Lux.cpu\nLux.gpu","category":"page"},{"location":"api/utilities/#Lux.cpu","page":"Utilities","title":"Lux.cpu","text":"cpu(x)\n\nTransfer x to CPU\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#Lux.gpu","page":"Utilities","title":"Lux.gpu","text":"gpu(x)\n\nTransfer x to GPU\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#Initialization","page":"Utilities","title":"Initialization","text":"","category":"section"},{"location":"api/utilities/","page":"Utilities","title":"Utilities","text":"Lux.glorot_normal\nLux.glorot_uniform\nLux.ones32\nLux.zeros32","category":"page"},{"location":"api/utilities/#Lux.glorot_normal","page":"Utilities","title":"Lux.glorot_normal","text":"glorot_normal(rng::AbstractRNG, size...; gain = 1)\n\nReturn an Array{Float32} of the given size containing random numbers drawn from a normal distribution with standard deviation gain * sqrt(2 / (fan_in + fan_out)). This method is described in [1] and also known as Xavier initialization.\n\nReferences\n\n[1] Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of training deep feedforward neural networks.\" Proceedings of the thirteenth international conference on artificial intelligence and statistics. 2010.\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#Lux.glorot_uniform","page":"Utilities","title":"Lux.glorot_uniform","text":"glorot_uniform(rng::AbstractRNG, size...; gain = 1)\n\nReturn an Array{Float32} of the given size containing random numbers drawn from a uniform distribution on the interval -x x, where x = gain * sqrt(6 / (fan_in + fan_out)). This method is described in [1] and also known as Xavier initialization.\n\nReferences\n\n[1] Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of training deep feedforward neural networks.\" Proceedings of the thirteenth international conference on artificial intelligence and statistics. 2010.\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#Lux.ones32","page":"Utilities","title":"Lux.ones32","text":"ones32(rng::AbstractRNG, size...) = ones(Float32, size...)\n\nReturn an Array{Float32} of ones of the given size. (rng is ignored)\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#Lux.zeros32","page":"Utilities","title":"Lux.zeros32","text":"zeros32(rng::AbstractRNG, size...) = zeros(Float32, size...)\n\nReturn an Array{Float32} of zeros of the given size. (rng is ignored)\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#Miscellaneous-Utilities","page":"Utilities","title":"Miscellaneous Utilities","text":"","category":"section"},{"location":"api/utilities/","page":"Utilities","title":"Utilities","text":"Lux.applyactivation\nLux.elementwise_add\nLux.elementwise_mul","category":"page"},{"location":"api/utilities/#Lux.applyactivation","page":"Utilities","title":"Lux.applyactivation","text":"applyactivation(f::Function, x::AbstractArray)\n\nApply the function f on x elementwise, i.e. f.(x). Dispatches to CUDNN if possible.\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#Lux.elementwise_add","page":"Utilities","title":"Lux.elementwise_add","text":"elementwise_add(x, y)\n\nComputes x .+ y. Dispatches to CUDNN if possible\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#Lux.elementwise_mul","page":"Utilities","title":"Lux.elementwise_mul","text":"elementwise_mul(x, y)\n\nComputes x .* y. Dispatches to CUDNN if possible\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#RNN-Utilities","page":"Utilities","title":"RNN Utilities","text":"","category":"section"},{"location":"api/utilities/","page":"Utilities","title":"Utilities","text":"Lux.multigate","category":"page"},{"location":"api/utilities/#Lux.multigate","page":"Utilities","title":"Lux.multigate","text":"multigate(x::AbstractArray, ::Val{N})\n\nSplit up x into N equally sized chunks (along dimension 1).\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#Index","page":"Utilities","title":"Index","text":"","category":"section"},{"location":"api/utilities/","page":"Utilities","title":"Utilities","text":"Pages = [\"utilities.md\"]","category":"page"},{"location":"design/recurrent/#Recurrent-Neural-Networks","page":"Recurrent Neural Networks","title":"Recurrent Neural Networks","text":"","category":"section"},{"location":"design/recurrent/#Cell-Implementations","page":"Recurrent Neural Networks","title":"Cell Implementations","text":"","category":"section"},{"location":"design/recurrent/#Explicit-Management-on-End-User-Side","page":"Recurrent Neural Networks","title":"Explicit Management on End-User Side","text":"","category":"section"},{"location":"design/recurrent/","page":"Recurrent Neural Networks","title":"Recurrent Neural Networks","text":"note: Note\nWe currently use this implementation","category":"page"},{"location":"design/recurrent/","page":"Recurrent Neural Networks","title":"Recurrent Neural Networks","text":"User is responsible for managing the memory and hidden states.","category":"page"},{"location":"design/recurrent/#Pros","page":"Recurrent Neural Networks","title":"Pros","text":"","category":"section"},{"location":"design/recurrent/","page":"Recurrent Neural Networks","title":"Recurrent Neural Networks","text":"Simple Design and Implementation\nHard for the User to mess up, i.e. there is no explicit requirement to call things like Flux.reset!\nIn the first call user passes the input\nIn the subsequent calls, the user passes a tuple containing the input, hidden_state and memory (if needed)","category":"page"},{"location":"design/recurrent/#Cons","page":"Recurrent Neural Networks","title":"Cons","text":"","category":"section"},{"location":"design/recurrent/","page":"Recurrent Neural Networks","title":"Recurrent Neural Networks","text":"Requires more explicit management from the user which might make it harder to use.\nCurrently the call order convention is not enforced which could lead to sneaky errors. (Implementing a check is quite trivial if we store a call counter in the model state)","category":"page"},{"location":"design/recurrent/#Store-Hidden-State-and-Memory-in-Model-State","page":"Recurrent Neural Networks","title":"Store Hidden State and Memory in Model State","text":"","category":"section"},{"location":"design/recurrent/","page":"Recurrent Neural Networks","title":"Recurrent Neural Networks","text":"Storing the memory and hidden state in st would allow user to just pass x without varying how calls are made at different timesteps","category":"page"},{"location":"design/recurrent/#Pros-2","page":"Recurrent Neural Networks","title":"Pros","text":"","category":"section"},{"location":"design/recurrent/","page":"Recurrent Neural Networks","title":"Recurrent Neural Networks","text":"Easier for the end-user","category":"page"},{"location":"design/recurrent/#Cons-2","page":"Recurrent Neural Networks","title":"Cons","text":"","category":"section"},{"location":"design/recurrent/","page":"Recurrent Neural Networks","title":"Recurrent Neural Networks","text":"reseting the hidden-state and memory is slightly tricky.\nOne way would be to store a initial_hidden_state and initial_memory in the state alongside the hidden_state and memory","category":"page"},{"location":"design/recurrent/#RNN-Blocks","page":"Recurrent Neural Networks","title":"RNN Blocks","text":"","category":"section"},{"location":"design/recurrent/","page":"Recurrent Neural Networks","title":"Recurrent Neural Networks","text":"note: Note\nThis is currently unimplemented","category":"page"},{"location":"design/recurrent/","page":"Recurrent Neural Networks","title":"Recurrent Neural Networks","text":"An example implementation would be","category":"page"},{"location":"design/recurrent/","page":"Recurrent Neural Networks","title":"Recurrent Neural Networks","text":"function (l::LSTM)(x::AbstractArray{T,3}, ps::NamedTuple, st::NamedTuple) where {T}\n    (h, c), st = s.lstm_cell(view(x, :, 1, :), ps, st)\n    for i in 1:size(x, 2)\n        (h, c), st = s.lstm_cell((view(x, :, i, :), h, c), ps, st)\n    end\n    return h, st\nend","category":"page"},{"location":"design/recurrent/","page":"Recurrent Neural Networks","title":"Recurrent Neural Networks","text":"We enforce the inputs to be of the format in_dims × sequence_length × batch_size","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"EditURL = \"https://github.com/avik-pal/Lux.jl/blob/main/examples/SimpleRNN/main.jl\"","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/#Training-a-Simple-LSTM","page":"SimpleRNN","title":"Training a Simple LSTM","text":"","category":"section"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"In this tutorial we will go over using a recurrent neural network to classify clockwise and anticlockwise spirals. By the end of this tutorial you will be able to:","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"Create custom Lux models\nBecome familiar with the Lux recurrent neural network API\nTraining using Optimisers.jl and Zygote.jl","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/#Package-Imports","page":"SimpleRNN","title":"Package Imports","text":"","category":"section"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"using Lux\nusing Pkg #hide\nPkg.activate(joinpath(dirname(pathof(Lux)), \"..\", \"examples\")) #hide\nusing MLUtils, Optimisers, Zygote, NNlib, Random, Statistics","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/#Dataset","page":"SimpleRNN","title":"Dataset","text":"","category":"section"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"We will use MLUtils to generate 500 (noisy) clockwise and 500 (noisy) anticlockwise spirals. Using this data we will create a MLUtils.DataLoader. Our dataloader will give us sequences of size 2 × seqlen × batchsize and we need to predict a binary value whether the sequence is clockwise or anticlockwise","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"function get_dataloaders(; dataset_size=1000, sequence_length=50)\n    # Create the spirals\n    data = [MLUtils.Datasets.make_spiral(sequence_length) for _ in 1:dataset_size]\n    # Get the labels\n    labels = vcat(repeat([0.0f0], dataset_size ÷ 2), repeat([1.0f0], dataset_size ÷ 2))\n    clockwise_spirals = [reshape(d[1][:, 1:sequence_length], :, sequence_length, 1) for d in data[1:(dataset_size ÷ 2)]]\n    anticlockwise_spirals = [\n        reshape(d[1][:, (sequence_length + 1):end], :, sequence_length, 1) for d in data[((dataset_size ÷ 2) + 1):end]\n    ]\n    x_data = Float32.(cat(clockwise_spirals..., anticlockwise_spirals...; dims=3))\n    # Split the dataset\n    (x_train, y_train), (x_val, y_val) = splitobs((x_data, labels); at=0.8, shuffle=true)\n    # Create DataLoaders\n    return (\n        # Use DataLoader to automatically minibatch and shuffle the data\n        DataLoader(collect.((x_train, y_train)); batchsize=128, shuffle=true),\n        # Don't shuffle the validation data\n        DataLoader(collect.((x_val, y_val)); batchsize=128, shuffle=false),\n    )\nend","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/#Creating-a-Classifier","page":"SimpleRNN","title":"Creating a Classifier","text":"","category":"section"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"We will be extending the Lux.AbstractExplicitContainerLayer type for our custom model since it will contain a lstm block and a classifier head.","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"We pass the fieldnames lstm_cell and classifier to the type to ensure that the parameters and states are automatically populated and we don't have to define Lux.initialparameters and Lux.initialstates.","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"struct SpiralClassifier{L,C} <: Lux.AbstractExplicitContainerLayer{(:lstm_cell, :classifier)}\n    lstm_cell::L\n    classifier::C\nend","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"We won't define the model from scratch but rather use the Lux.LSTMCell and Lux.Dense","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"function SpiralClassifier(in_dims, hidden_dims, out_dims)\n    return SpiralClassifier(LSTMCell(in_dims => hidden_dims), Dense(hidden_dims => out_dims, sigmoid))\nend","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"Now we need to define the behavior of the Classifier when it is invoked","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"function (s::SpiralClassifier)(x::AbstractArray{T,3}, ps::NamedTuple, st::NamedTuple) where {T}\n    # First we will have to run the sequence through the LSTM Cell\n    # The first call to LSTM Cell will create the initial hidden state\n    # See that the parameters and states are automatically populated into a field called `lstm_cell`\n    # We use `view(x, :, 1, :)` to get the first element in the sequence without copying it\n    (h, c), st_lstm = s.lstm_cell(view(x, :, 1, :), ps.lstm_cell, st.lstm_cell)\n    # Now that we have the hidden state we will pass the input and hidden state jointly\n    for i in 1:size(x, 2)\n        (h, c), st_lstm = s.lstm_cell((view(x, :, i, :), h, c), ps.lstm_cell, st_lstm)\n    end\n    # After running through the sequence we will pass the output through the classifier\n    y, st_classifier = s.classifier(h, ps.classifier, st.classifier)\n    # Finally remember to create the updated state\n    st = merge(st, (classifier=st_classifier, lstm_cell=st_lstm))\n    return vec(y), st\nend","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/#Defining-Accuracy,-Loss-and-Optimiser","page":"SimpleRNN","title":"Defining Accuracy, Loss and Optimiser","text":"","category":"section"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"Now let's define the binarycrossentropy loss. Typically it is recommended to use logitbinarycrossentropy since it is more numerically stable, but for the sake of simplicity we will use binarycrossentropy","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"function xlogy(x, y)\n    result = x * log(y)\n    return ifelse(iszero(x), zero(result), result)\nend\n\nfunction binarycrossentropy(y_pred, y_true)\n    y_pred = y_pred .+ eps(eltype(y_pred))\n    return mean(@. -xlogy(y_true, y_pred) - xlogy(1 - y_true, 1 - y_pred))\nend\n\nfunction compute_loss(x, y, model, ps, st)\n    y_pred, st = model(x, ps, st)\n    return binarycrossentropy(y_pred, y), y_pred, st\nend\n\nmatches(y_pred, y_true) = sum((y_pred .> 0.5) .== y_true)\naccuracy(y_pred, y_true) = matches(y_pred, y_true) / length(y_pred)","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"Finally lets create an optimiser given the model parameters","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"function create_optimiser(ps)\n    opt = Optimisers.ADAM(0.01f0)\n    return Optimisers.setup(opt, ps)\nend","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/#Training-the-Model","page":"SimpleRNN","title":"Training the Model","text":"","category":"section"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"function main()\n    # Get the dataloaders\n    (train_loader, val_loader) = get_dataloaders()\n\n    # Create the model\n    model = SpiralClassifier(2, 8, 1)\n    rng = Random.default_rng()\n    Random.seed!(rng, 0)\n    ps, st = Lux.setup(rng, model)\n\n    # Create the optimiser\n    opt_state = create_optimiser(ps)\n\n    for epoch in 1:25\n        # Train the model\n        for (x, y) in train_loader\n            (loss, y_pred, st), back = pullback(p -> compute_loss(x, y, model, p, st), ps)\n            gs = back((one(loss), nothing, nothing))[1]\n            opt_state, ps = Optimisers.update(opt_state, ps, gs)\n\n            println(\"Epoch [$epoch]: Loss $loss\")\n        end\n\n        # Validate the model\n        st_ = Lux.testmode(st)\n        for (x, y) in val_loader\n            (loss, y_pred, st_) = compute_loss(x, y, model, ps, st_)\n            acc = accuracy(y_pred, y)\n            println(\"Validation: Loss $loss Accuracy $acc\")\n        end\n    end\nend\n\nmain()","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"","category":"page"},{"location":"examples/generated/beginner/SimpleRNN/main/","page":"SimpleRNN","title":"SimpleRNN","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"EditURL = \"https://github.com/avik-pal/Lux.jl/blob/main/examples/NeuralODE/main.jl\"","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/#MNIST-Classification-using-Neural-ODEs","page":"NeuralODE","title":"MNIST Classification using Neural ODEs","text":"","category":"section"},{"location":"examples/generated/intermediate/NeuralODE/main/#Package-Imports","page":"NeuralODE","title":"Package Imports","text":"","category":"section"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"using Lux\nusing Pkg #hide\nPkg.activate(joinpath(dirname(pathof(Lux)), \"..\", \"examples\")) #hide\nusing ComponentArrays, CUDA, DiffEqSensitivity, NNlib, Optimisers, OrdinaryDiffEq, Random, Statistics, Zygote\nimport MLDatasets: MNIST\nimport MLDataUtils: convertlabel, LabelEnc\nimport MLUtils: DataLoader, splitobs\nCUDA.allowscalar(false)","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/#Loading-MNIST","page":"NeuralODE","title":"Loading MNIST","text":"","category":"section"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"# Use MLDataUtils LabelEnc for natural onehot conversion\nonehot(labels_raw) = convertlabel(LabelEnc.OneOfK, labels_raw, LabelEnc.NativeLabels(collect(0:9)))\n\nfunction loadmnist(batchsize, train_split)\n    # Load MNIST: Only 1500 for demonstration purposes\n    N = 1500\n    imgs = MNIST.traintensor(1:N)\n    labels_raw = MNIST.trainlabels(1:N)\n\n    # Process images into (H,W,C,BS) batches\n    x_data = Float32.(reshape(imgs, size(imgs, 1), size(imgs, 2), 1, size(imgs, 3)))\n    y_data = onehot(labels_raw)\n    (x_train, y_train), (x_test, y_test) = splitobs((x_data, y_data); at=train_split)\n\n    return (\n        # Use DataLoader to automatically minibatch and shuffle the data\n        DataLoader(collect.((x_train, y_train)); batchsize=batchsize, shuffle=true),\n        # Don't shuffle the test data\n        DataLoader(collect.((x_test, y_test)); batchsize=batchsize, shuffle=false),\n    )\nend","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/#Define-the-Neural-ODE-Layer","page":"NeuralODE","title":"Define the Neural ODE Layer","text":"","category":"section"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"The NeuralODE is a ContainerLayer. It stores a model and the parameters and states of the NeuralODE is same as that of the underlying model.","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"struct NeuralODE{M<:Lux.AbstractExplicitLayer,So,Se,T,K} <: Lux.AbstractExplicitContainerLayer{(:model,)}\n    model::M\n    solver::So\n    sensealg::Se\n    tspan::T\n    kwargs::K\nend\n\nfunction NeuralODE(\n    model::Lux.AbstractExplicitLayer;\n    solver=Tsit5(),\n    sensealg=InterpolatingAdjoint(; autojacvec=ZygoteVJP()),\n    tspan=(0.0f0, 1.0f0),\n    kwargs...,\n)\n    return NeuralODE(model, solver, sensealg, tspan, kwargs)\nend\n\nfunction (n::NeuralODE)(x, ps, st)\n    function dudt(u, p, t)\n        u_, st = n.model(u, p, st)\n        return u_\n    end\n    prob = ODEProblem{false}(ODEFunction{false}(dudt), x, n.tspan, ps)\n    return solve(prob, n.solver; sensealg=n.sensealg, n.kwargs...), st\nend\n\ndiffeqsol_to_array(x::ODESolution{T,N,<:AbstractVector{<:CuArray}}) where {T,N} = dropdims(gpu(x); dims=3)\ndiffeqsol_to_array(x::ODESolution) = dropdims(Array(x); dims=3)","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/#Create-and-Initialize-the-Neural-ODE-Layer","page":"NeuralODE","title":"Create and Initialize the Neural ODE Layer","text":"","category":"section"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"function create_model()\n    # Construct the Neural ODE Model\n    model = Chain(\n        FlattenLayer(),\n        Dense(784, 20, tanh),\n        NeuralODE(\n            Chain(Dense(20, 10, tanh), Dense(10, 10, tanh), Dense(10, 20, tanh));\n            save_everystep=false,\n            reltol=1.0f-3,\n            abstol=1.0f-3,\n            save_start=false,\n        ),\n        diffeqsol_to_array,\n        Dense(20, 10),\n    )\n\n    rng = Random.default_rng()\n    Random.seed!(rng, 0)\n\n    ps, st = Lux.setup(rng, model)\n    ps = ComponentArray(ps) |> gpu\n    st = st |> gpu\n\n    return model, ps, st\nend","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/#Define-Utility-Functions","page":"NeuralODE","title":"Define Utility Functions","text":"","category":"section"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"get_class(x) = argmax.(eachcol(x))\n\nlogitcrossentropy(ŷ, y) = mean(-sum(y .* logsoftmax(ŷ); dims = 1))\n\nfunction loss(x, y, model, ps, st)\n    ŷ, st = model(x, ps, st)\n    return logitcrossentropy(ŷ, y), st\nend\n\nfunction accuracy(model, ps, st, dataloader)\n    total_correct, total = 0, 0\n    st = Lux.testmode(st)\n    iterator = CUDA.functional() ? CuIterator(dataloader) : dataloader\n    for (x, y) in iterator\n        target_class = get_class(cpu(y))\n        predicted_class = get_class(cpu(model(x, ps, st)[1]))\n        total_correct += sum(target_class .== predicted_class)\n        total += length(target_class)\n    end\n    return total_correct / total\nend","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/#Training","page":"NeuralODE","title":"Training","text":"","category":"section"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"function train()\n    model, ps, st = create_model()\n\n    # Training\n    train_dataloader, test_dataloader = loadmnist(128, 0.9)\n\n    opt = Optimisers.ADAM(0.001f0)\n    st_opt = Optimisers.setup(opt, ps)\n\n    ### Warmup the Model\n    img, lab = gpu(train_dataloader.data[1][:, :, :, 1:1]), gpu(train_dataloader.data[2][:, 1:1])\n    loss(img, lab, model, ps, st)\n    (l, _), back = pullback(p -> loss(img, lab, model, p, st), ps)\n    back((one(l), nothing))\n\n    ### Lets train the model\n    nepochs = 9\n    for epoch in 1:nepochs\n        stime = time()\n        iterator = CUDA.functional() ? CuIterator(train_dataloader) : train_dataloader\n        for (x, y) in iterator\n            (l, _), back = pullback(p -> loss(x, y, model, p, st), ps)\n            gs = back((one(l), nothing))[1]\n            st_opt, ps = Optimisers.update(st_opt, ps, gs)\n        end\n        ttime = time() - stime\n\n        println(\n            \"[$epoch/$nepochs] \\t Time $(round(ttime; digits=2))s \\t Training Accuracy: \" *\n            \"$(round(accuracy(model, ps, st, train_dataloader) * 100; digits=2))% \\t \" *\n            \"Test Accuracy: $(round(accuracy(model, ps, st, test_dataloader) * 100; digits=2))%\"\n        )\n    end\nend\n\ntrain()","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"This page was generated using Literate.jl.","category":"page"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"CurrentModule = Lux","category":"page"},{"location":"api/layers/#Containers","page":"Layers","title":"Containers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"BranchLayer\nChain\nPairwiseFusion\nParallel\nSkipConnection","category":"page"},{"location":"api/layers/#Lux.BranchLayer","page":"Layers","title":"Lux.BranchLayer","text":"BranchLayer(layers...)\n\nTakes an input x and passes it through all the layers and returns a tuple of the outputs.\n\nThis is slightly different from Parallel(nothing, layers...)     - If the input is a tuple Parallel will pass each element individually to each layer     - BranchLayer essentially assumes 1 input comes in and is branched out into N outputs\n\nAn easy way to replicate an input to an NTuple is to do\n\nl = BranchLayer(\n        NoOpLayer(),\n        NoOpLayer(),\n        NoOpLayer(),\n    )\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.Chain","page":"Layers","title":"Lux.Chain","text":"Chain(layers...; disable_optimizations::Bool = false)\n\nCollects multiple layers / functions to be called in sequence on a given input.\n\nPerforms a few optimizations to generate reasonable architectures. Can be disabled using keyword argument disable_optimizations.\n\nAll sublayers are recursively optimized.\nIf a function f is passed as a layer and it doesn't take 3 inputs, it is converted to a WrappedFunction(f) which takes only one input.\nIf the layer is a Chain, it is expanded out.\nNoOpLayers are removed.\nIf there is only 1 layer (left after optimizations), then it is returned without the Chain wrapper.\nIf there are no layers (left after optimizations), a NoOpLayer is returned.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.PairwiseFusion","page":"Layers","title":"Lux.PairwiseFusion","text":"PairwiseFusion(connection, layers...)\n\nLayer behaves differently based on input type:\n\nInput x is a tuple of length N then the layers must be a tuple of length N. The computation is as follows\n\ny = x[1]\nfor i in 1:N\n    y = connection(x[i], layers[i](y))\nend\n\nAny other kind of input\n\ny = x\nfor i in 1:N\n    y = connection(x, layers[i](y))\nend\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.Parallel","page":"Layers","title":"Lux.Parallel","text":"Parallel(connection, layers...)\n\nBehaves differently on different input types:\n\nIf x is a Tuple then each element is passed to each layer\nOtherwise, x is directly passed to all layers\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.SkipConnection","page":"Layers","title":"Lux.SkipConnection","text":"SkipConnection(layer, connection)\n\nCreate a skip connection which consists of a layer or Chain of consecutive layers and a shortcut connection linking the block's input to the output through a user-supplied 2-argument callable. The first argument to the callable will be propagated through the given layer while the second is the unchanged, \"skipped\" input.\n\nThe simplest \"ResNet\"-type connection is just SkipConnection(layer, +).\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Convolutional-Layers","page":"Layers","title":"Convolutional Layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Conv","category":"page"},{"location":"api/layers/#Lux.Conv","page":"Layers","title":"Lux.Conv","text":"Conv(filter, in => out, σ = identity; stride = 1, pad = 0, dilation = 1, groups = 1, [bias, init_weight])\n\nStandard convolutional layer.\n\nArguments\n\nfilter is a tuple of integers specifying the size of the convolutional kernel\nin and out specify the number of input and output channels.\n\nImage data should be stored in WHCN order (width, height, channels, batch). In other words, a 100×100 RGB image would be a 100×100×3×1 array, and a batch of 50 would be a 100×100×3×50 array. This has N = 2 spatial dimensions, and needs a kernel size like (5,5), a 2-tuple of integers. To take convolutions along N feature dimensions, this layer expects as input an array with ndims(x) == N+2, where size(x, N+1) == in is the number of input channels, and size(x, ndims(x)) is (as always) the number of observations in a batch.\n\nfilter should be a tuple of N integers.\nKeywords stride and dilation should each be either single integer, or a tuple with N integers.\nKeyword pad specifies the number of elements added to the borders of the data array. It can be\na single integer for equal padding all around,\na tuple of N integers, to apply the same padding at begin/end of each spatial dimension,\na tuple of 2*N integers, for asymmetric padding, or\nthe singleton SamePad(), to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension.\nKeyword groups is expected to be an Int. It specifies the number of groups to divide a convolution into.\n\nKeywords to control initialization of the layer:\n\ninit_weight - Function used to generate initial weights. Defaults to glorot_uniform.\nbias - The initial bias vector is all zero by default. Trainable bias can be disabled entirely by setting this to false.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Dropout-Layers","page":"Layers","title":"Dropout Layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Dropout\nVariationalHiddenDropout","category":"page"},{"location":"api/layers/#Lux.Dropout","page":"Layers","title":"Lux.Dropout","text":"Dropout(p; dims=:)\n\nDropout layer.\n\nArguments\n\nTo apply dropout along certain dimension(s), specify the dims keyword. e.g. Dropout(p; dims = 3) will randomly zero out entire channels on WHCN input (also called 2D dropout).\nEach execution of the Layer increments the seed and returns it wrapped in the state\n\nCall Lux.testmode to switch to test mode.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.VariationalHiddenDropout","page":"Layers","title":"Lux.VariationalHiddenDropout","text":"VariationalHiddenDropout(p; dims=:)\n\nVariationalHiddenDropout layer. The only difference from Dropout is that the mask is retained until Lux.update_state(l, :update_mask, Val(true)) is called.\n\nArguments\n\nTo apply dropout along certain dimension(s), specify the dims keyword. e.g. Dropout(p; dims = 3) will randomly zero out entire channels on WHCN input (also called 2D dropout).\nEach execution of the Layer increments the seed and returns it wrapped in the state\n\nCall Lux.testmode to switch to test mode.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Pooling-Layers","page":"Layers","title":"Pooling Layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"AdaptiveMaxPool\nAdaptiveMeanPool\nGlobalMaxPool\nGlobalMeanPool\nMaxPool\nMeanPool","category":"page"},{"location":"api/layers/#Lux.AdaptiveMaxPool","page":"Layers","title":"Lux.AdaptiveMaxPool","text":"AdaptiveMaxPool(out::NTuple)\n\nAdaptive Max Pooling layer. Calculates the necessary window size such that its output has size(y)[1:N] == out. Expects as input an array with ndims(x) == N+2, i.e. channel and batch dimensions, after the N feature dimensions, where N = length(out).\n\nSee also MaxPool, AdaptiveMeanPool.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.AdaptiveMeanPool","page":"Layers","title":"Lux.AdaptiveMeanPool","text":"AdaptiveMeanPool(out::NTuple)\n\nAdaptive Mean Pooling layer. Calculates the necessary window size such that its output has size(y)[1:N] == out. Expects as input an array with ndims(x) == N+2, i.e. channel and batch dimensions, after the N feature dimensions, where N = length(out).\n\nSee also MaxPool, AdaptiveMaxPool.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.GlobalMaxPool","page":"Layers","title":"Lux.GlobalMaxPool","text":"GlobalMaxPool()\n\nGlobal Max Pooling layer. Transforms (w,h,c,b)-shaped input into (1,1,c,b)-shaped output, by performing max pooling on the complete (w,h)-shaped feature maps.\n\nSee also MaxPool, GlobalMeanPool.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.GlobalMeanPool","page":"Layers","title":"Lux.GlobalMeanPool","text":"GlobalMeanPool()\n\nGlobal Mean Pooling layer. Transforms (w,h,c,b)-shaped input into (1,1,c,b)-shaped output, by performing max pooling on the complete (w,h)-shaped feature maps.\n\nSee also MeanPool, GlobalMaxPool.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.MaxPool","page":"Layers","title":"Lux.MaxPool","text":"MaxPool(window::NTuple; pad=0, stride=window)\n\nArguments\n\nMax pooling layer, which replaces all pixels in a block of size window with one.\nExpects as input an array with ndims(x) == N+2, i.e. channel and batch dimensions, after the N feature dimensions, where N = length(window).\nBy default the window size is also the stride in each dimension.\nThe keyword pad accepts the same options as for the Conv layer, including SamePad().\n\nSee also Conv, MeanPool, GlobalMaxPool.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.MeanPool","page":"Layers","title":"Lux.MeanPool","text":"MeanPool(window::NTuple; pad=0, stride=window)\n\nArguments\n\nMean pooling layer, which replaces all pixels in a block of size window with one.\nExpects as input an array with ndims(x) == N+2, i.e. channel and batch dimensions, after the N feature dimensions, where N = length(window).\nBy default the window size is also the stride in each dimension.\nThe keyword pad accepts the same options as for the Conv layer, including SamePad().\n\nSee also Conv, MaxPool, GlobalMeanPool.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Recurrent-Layers","page":"Layers","title":"Recurrent Layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"warn: Warn\nRecurrent Layers API should be considered Experimental at this point","category":"page"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"GRUCell\nLSTMCell\nRNNCell","category":"page"},{"location":"api/layers/#Lux.GRUCell","page":"Layers","title":"Lux.GRUCell","text":"GRUCell((in_dims, out_dims)::Pair{<:Int,<:Int}; init_weight::Tuple{Function,Function,Function}=(glorot_uniform, glorot_uniform, glorot_uniform), init_bias::Tuple{Function,Function,Function}=(zeros32, zeros32, zeros32), init_state::Function=zeros32)\n\nGated Recurrent Unit (GRU) Cell\n\nr = sigma(W_ir times x + W_hr times h_prev + b_hr)\n\nz = sigma(W_iz times x + W_hz times h_prev + b_hz)\n\nn = sigma(W_in times x + b_in + r cdot (W_hn times h_prev + b_hn))\n\nh_new = (1 - z) cdot n + z cdot h_prev\n\nArguments\n\nin_dims: Input Dimension\nout_dims: Output (Hidden State) Dimension\ninit_bias: Initializer for bias. Must be a tuple containing 3 functions\ninit_weight: Initializer for weight. Must be a tuple containing 3 functions\ninit_state: Initializer for hidden state\n\nInputs\n\nCase 1: Only a single input x of shape (in_dims, batch_size) - Creates a hidden state using init_state and proceeds to Case 2.\nCase 2: Tuple (x, h) is provided, then the updated hidden state is returned.\n\nOutputs\n\nNew hidden state h_new of shape (out_dims, batch_size)\nUpdated model state\n\nParameters\n\nweight_i: Concatenated Weights to map from input space left W_ir W_iz W_in right.\nweight_h: Concatenated Weights to map from hidden space left W_hr W_hz W_hn right\nbias_i: Bias vector (b_in)\nbias_h: Concatenated Bias vector for the hidden space left b_hr b_hz b_hn right\n\nStates\n\nrng: Controls the randomness (if any) in the initial state generation\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.LSTMCell","page":"Layers","title":"Lux.LSTMCell","text":"LSTMCell(in_dims => out_dims; init_weight=(glorot_uniform, glorot_uniform, glorot_uniform, glorot_uniform), init_bias=(zeros32, zeros32, ones32, zeros32), init_state=zeros32)\n\nLong Short-Term (LSTM) Cell\n\ni = sigma(W_ii times x + W_hi times h_prev + b_i)\n\nf = sigma(W_if times x + W_hf times h_prev + b_f)\n\ng = tanh(W_ig times x + W_hg times h_prev + b_g)\n\no = sigma(W_io times x + W_ho times h_prev + b_o)\n\nc_new = f cdot c_prev + i cdot g\n\nh_new = o cdot tanh(c_new)\n\nArguments\n\nin_dims: Input Dimension\nout_dims: Output (Hidden State & Memory) Dimension\ninit_bias: Initializer for bias. Must be a tuple containing 4 functions\ninit_weight: Initializer for weight. Must be a tuple containing 4 functions\ninit_state: Initializer for hidden state and memory\n\nInputs\n\nCase 1: Only a single input x of shape (in_dims, batch_size) - Creates a hidden state and memory using init_state and proceeds to Case 2.\nCase 2: Tuple (x, h, c) is provided, then the updated hidden state and memory is returned.\n\nOutputs\n\nTuple Containing\nNew hidden state h_new of shape (out_dims, batch_size)\nUpdated Memory c_new of shape (out_dims, batch_size)\nUpdated model state\n\nParameters\n\nweight_i: Concatenated Weights to map from input space left W_ii W_if W_ig W_io right.\nweight_h: Concatenated Weights to map from hidden space left W_hi W_hf W_hg W_ho right\nbias: Bias vector\n\nStates\n\nrng: Controls the randomness (if any) in the initial state generation\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.RNNCell","page":"Layers","title":"Lux.RNNCell","text":"RNNCell(in_dims => out_dims, activation=tanh; bias::Bool=true, init_bias=zeros32, init_weight=glorot_uniform, init_state=ones32)\n\nAn Elman RNNCell cell with activation (typically set to tanh or relu).\n\nh_new = activation(weight_ih times x + weight_hh times h_prev + bias)\n\nArguments\n\nin_dims: Input Dimension\nout_dims: Output (Hidden State) Dimension\nactivation: Activation function\nbias: Set to false to deactivate bias\ninit_bias: Initializer for bias\ninit_weight: Initializer for weight\ninit_state: Initializer for hidden state\n\nInputs\n\nCase 1: Only a single input x of shape (in_dims, batch_size) - Creates a hidden state using init_state and proceeds to Case 2.\nCase 2: Tuple (x, h) is provided, then the updated hidden state is returned.\n\nOutputs\n\nNew hidden state h_new of shape (out_dims, batch_size)\nUpdated model state\n\nParameters\n\nweight_ih: Maps the input to the hidden state.\nweight_hh: Maps the hidden state to the hidden state.\nbias: Bias vector (not present if bias=false)\n\nStates\n\nrng: Controls the randomness (if any) in the initial state generation\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Linear-Layers","page":"Layers","title":"Linear Layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Dense\nScale","category":"page"},{"location":"api/layers/#Lux.Dense","page":"Layers","title":"Lux.Dense","text":"Dense(in => out, σ=identity; init_weight=glorot_uniform, init_bias=zeros32, bias::Bool=true)\n\nCreate a traditional fully connected layer, whose forward pass is given by: y = σ.(weight * x .+ bias)\n\nThe input x should be a vector of length in, or batch of vectors represented as an in × N matrix, or any array with size(x,1) == in.\nThe output y will be a vector  of length out, or a batch with size(y) == (out, size(x)[2:end]...)\n\nKeyword bias=false will switch off trainable bias for the layer.\n\nThe initialisation of the weight matrix is W = init_weight(rng, out, in), calling the function given to keyword init_weight, with default glorot_uniform.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.Scale","page":"Layers","title":"Lux.Scale","text":"Scale(dims, σ=identity; init_weight=ones32, init_bias=zeros32, bias::Bool=true)\n\nCreate a Sparsely Connected Layer with a very specific structure (only Diagonal Elements are non-zero). The forward pass is given by: y = σ.(weight .* x .+ bias)\n\nThe input x should be a vector of length dims, or batch of vectors represented as an in × N matrix, or any array with size(x,1) == in.\nThe output y will be a vector  of length dims, or a batch with size(y) == (dims, size(x)[2:end]...)\n\nKeyword bias=false will switch off trainable bias for the layer.\n\nThe initialisation of the weight matrix is W = init_weight(rng, dims), calling the function given to keyword init_weight, with default glorot_uniform.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Misc.-Helper-Layers","page":"Layers","title":"Misc. Helper Layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"ActivationFunction\nFlattenLayer\nNoOpLayer\nReshapeLayer\nSelectDim\nWrappedFunction","category":"page"},{"location":"api/layers/#Lux.ActivationFunction","page":"Layers","title":"Lux.ActivationFunction","text":"ActivationFunction(f)\n\nBroadcast f on the input but fallback to CUDNN for Backward Pass\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.FlattenLayer","page":"Layers","title":"Lux.FlattenLayer","text":"FlattenLayer()\n\nFlattens the passed array into a matrix.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.NoOpLayer","page":"Layers","title":"Lux.NoOpLayer","text":"NoOpLayer()\n\nAs the name suggests does nothing but allows pretty printing of layers.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.ReshapeLayer","page":"Layers","title":"Lux.ReshapeLayer","text":"ReshapeLayer(dims)\n\nReshapes the passed array to have a size of (dims..., :)\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.SelectDim","page":"Layers","title":"Lux.SelectDim","text":"SelectDim(dim, i)\n\nSee the documentation for selectdim for more information.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.WrappedFunction","page":"Layers","title":"Lux.WrappedFunction","text":"WrappedFunction(f)\n\nWraps a stateless and parameter less function. Might be used when a function is added to Chain. For example, Chain(x -> relu.(x)) would not work and the right thing to do would be Chain((x, ps, st) -> (relu.(x), st)). An easier thing to do would be Chain(WrappedFunction(Base.Fix1(broadcast, relu)))\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Normalization-Layers","page":"Layers","title":"Normalization Layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"BatchNorm\nGroupNorm\nWeightNorm","category":"page"},{"location":"api/layers/#Lux.BatchNorm","page":"Layers","title":"Lux.BatchNorm","text":"BatchNorm(chs::Integer, activation=identity; init_bias=zeros32, init_scale=ones32,\n          affine = true, track_stats = true, epsilon=1f-5, momentum= 0.1f0)\n\nBatch Normalization layer.\n\nBatchNorm computes the mean and variance for each D_1×...×D_{N-2}×1×D_N input slice and normalises the input accordingly.\n\nArguments\n\nchs should be the size of the channel dimension in your data (see below). Given an array with N dimensions, call the N-1th the channel dimension. For a batch of feature vectors this is just the data dimension, for WHCN images it's the usual channel dimension.\nAfter normalisation, elementwise activation activation is applied.\nIf affine=true, it also applies  a shift and a rescale to the input through to learnable per-channel bias bias and scale scale parameters.\nIf track_stats=true, accumulates mean and var statistics in training phase that will be used to renormalize the input in test phase.\n\nUse Lux.testmode during inference.\n\nExamples\n\nm = Chain(\n        Dense(784 => 64),\n        BatchNorm(64, relu),\n        Dense(64 => 10),\n        BatchNorm(10)\n    )\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.GroupNorm","page":"Layers","title":"Lux.GroupNorm","text":"GroupNorm(chs::Integer, groups::Integer, activation=identity; init_bias=zeros32, init_scale=ones32,\n          affine=true, track_stats=false, epsilon=1f-5, momentum=0.1f0)\n\nGroup Normalization layer.\n\nArguments\n\nchs is the number of channels, the channel dimension of your input. For an array of N dimensions, the N-1th index is the channel dimension.\ngroups is the number of groups along which the statistics are computed. The number of channels must be an integer multiple of the number of groups.\nAfter normalisation, elementwise activation activation is applied.\nIf affine=true, it also applies  a shift and a rescale to the input through to learnable per-channel bias bias and scale scale parameters.\nIf track_stats=true, accumulates mean and var statistics in training phase that will be used to renormalize the input in test phase.\n\nwarn: Warn\nGroupNorm doesn't have CUDNN support. The GPU fallback is not very efficient.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.WeightNorm","page":"Layers","title":"Lux.WeightNorm","text":"WeightNorm(layer::AbstractExplicitLayer, which_params::NTuple{N,Symbol}, dims::Union{Tuple,Nothing}=nothing)\n\nApplies weight normalization to a parameter in the given layer.\n\nw = gfracvv\n\nWeight normalization is a reparameterization that decouples the magnitude of a weight tensor from its direction. This updates the parameters in which_params (e.g. weight) using two parameters: one specifying the magnitude (e.g. weight_g) and one specifying the direction (e.g. weight_v).\n\nBy default, a norm over the entire array is computed. Pass dims to modify the dimension.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Upsampling","page":"Layers","title":"Upsampling","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Upsample","category":"page"},{"location":"api/layers/#Lux.Upsample","page":"Layers","title":"Lux.Upsample","text":"Upsample(mode = :nearest; [scale, size]) \nUpsample(scale, mode = :nearest)\n\nAn upsampling layer.\n\nArguments\n\nOne of two keywords must be given:\n\nIf scale is a number, this applies to all but the last two dimensions (channel and batch) of the input.  It may also be a tuple, to control dimensions individually.\nAlternatively, keyword size accepts a tuple, to directly specify the leading dimensions of the output.\n\nCurrently supported upsampling modes and corresponding NNlib's methods are:\n\n:nearest -> NNlib.upsample_nearest\n:bilinear -> NNlib.upsample_bilinear\n:trilinear -> NNlib.upsample_trilinear\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Index","page":"Layers","title":"Index","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Pages = [\"layers.md\"]","category":"page"},{"location":"introduction/overview/#Why-we-wrote-Lux?","page":"All about Lux","title":"Why we wrote Lux?","text":"","category":"section"},{"location":"introduction/overview/","page":"All about Lux","title":"All about Lux","text":"Julia already has quite a few well established Neural Network Frameworks – Flux & KNet. However, certain design elements – Coupled Model and Parameters & Internal Mutations – associated with these frameworks make them less compiler and user friendly. Making changes to address these problems in the respective frameworks would be too disruptive for users. Here comes in Lux a neural network framework built completely using pure functions to make it both compiler and autodiff friendly.","category":"page"},{"location":"introduction/overview/#Design-Principles","page":"All about Lux","title":"Design Principles","text":"","category":"section"},{"location":"introduction/overview/","page":"All about Lux","title":"All about Lux","text":"Layers must be immutable – cannot store any parameter/state but rather store the information to construct them\nLayers are pure functions\nLayers return a Tuple containing the result and the updated state\nGiven same inputs the outputs must be same – yes this must hold true even for stochastic functions. Randomness must be controlled using rngs passed in the state.\nEasily extendible","category":"page"},{"location":"introduction/overview/#AbstractExplicitLayer-API","page":"All about Lux","title":"AbstractExplicitLayer API","text":"","category":"section"},{"location":"introduction/overview/","page":"All about Lux","title":"All about Lux","text":"We provide 2 abstract layers:","category":"page"},{"location":"introduction/overview/","page":"All about Lux","title":"All about Lux","text":"AbstractExplicitLayer: Useful for Base Layers and needs to define the following functions\ninitialparameters(rng::AbstractRNG, layer::CustomAbstractExplicitLayer) – This returns a ComponentArray/NamedTuple containing the trainable parameters for the layer.\ninitialstates(rng::AbstractRNG, layer::CustomAbstractExplicitLayer) – This returns a NamedTuple containing the current state for the layer. For most layers this is typically empty. Layers that would potentially contain this include BatchNorm, LSTM, GRU etc.\nparameterlength(layer::CustomAbstractExplicitLayer) – These can be automatically calculated, but it is recommended that the user defines these.\nstatelength(layer::CustomAbstractExplicitLayer) – These can be automatically calculated, but it is recommended that the user defines these.\nAbstractExplicitContainerLayer: Used when the layer is storing other AbstractExplicitLayers or AbstractExplicitContainerLayers. This allows good defaults of the dispatches for functions mentioned in the previous point.","category":"page"},{"location":"introduction/overview/","page":"All about Lux","title":"All about Lux","text":"note: Note\nWe recommend users to subtype their custom layers using AbstractExplicitLayer or AbstractExplicitContainerLayer. However, this is not mandatory.","category":"page"},{"location":"introduction/overview/#Why-use-Lux-over-Flux?","page":"All about Lux","title":"Why use Lux over Flux?","text":"","category":"section"},{"location":"introduction/overview/","page":"All about Lux","title":"All about Lux","text":"Large Neural Networks\nFor small neural networks we recommend SimpleChains.jl.\nFor SciML Applications (Neural ODEs, Deep Equilibrium Models) solvers typically expect a monolithic parameter vector. Flux enables this via its destructure mechanism, however, it often leads to weird bugs. Lux forces users to make an explicit distinction between state variables and parameter variables to avoid these issues.\nComes battery-included for distributed training using FluxMPI.jl\nSensible display of Custom Layers – Ever wanted to see Pytorch like Network printouts or wondered how to extend the pretty printing of Flux's layers. Lux handles all of that by default.\nLess Bug-ridden Code\nNo arbitrary internal mutations – all layers are implemented as pure functions.\nAll layers are deterministic given the parameter and state – if the layer is supposed to be stochastic (say Dropout), the state must contain a seed which is then updated after the function call.\nEasy Parameter Manipulation – Wondering why Flux doesn't have WeightNorm, SpectralNorm, etc. The implicit parameter handling makes it extremely hard to pass parameters around without mutations which AD systems don't like. With Lux implementing them is outright simple.","category":"page"},{"location":"examples/","page":"Additional Examples","title":"Additional Examples","text":"warn: Warn\nThese were not written in the form of tutorials but standalone scripts/packages for people to use","category":"page"},{"location":"examples/#Packages","page":"Additional Examples","title":"Packages","text":"","category":"section"},{"location":"examples/","page":"Additional Examples","title":"Additional Examples","text":"Deep Equilibrium Models","category":"page"},{"location":"examples/#Scipts","page":"Additional Examples","title":"Scipts","text":"","category":"section"},{"location":"examples/","page":"Additional Examples","title":"Additional Examples","text":"ImageNet Classification using Metalhead.jl Models","category":"page"},{"location":"#Lux","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux","text":"","category":"section"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"Lux is a julia deep learning framework which decouples models and parameterization using deeply nested named tuples.","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"Functional Layer API – Pure Functions and Deterministic Function Calls.\nNo more implicit parameterization – Zygote.Params. Everything is a NamedTuple.\nCompiler and AD-friendly Neural Networks","category":"page"},{"location":"#Installation","page":"Lux: Explicitly Parameterized Neural Networks","title":"Installation","text":"","category":"section"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"Install julia v1.6 or above.","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"using Pkg\nPkg.add(\"Lux\")","category":"page"},{"location":"#Quick-Example","page":"Lux: Explicitly Parameterized Neural Networks","title":"Quick Example","text":"","category":"section"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"using Lux, Random, Optimisers, Zygote","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"We take randomness very seriously","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"# Seeding\nrng = Random.default_rng()\nRandom.seed!(rng, 0)","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"Build the model","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"# Construct the layer\nmodel = Chain(\n    BatchNorm(128),\n    Dense(128, 256, tanh),\n    BatchNorm(256),\n    Chain(\n        Dense(256, 1, tanh),\n        Dense(1, 10)\n    )\n)","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"Models don't hold parameters and states so initialize them. From there on, we just use our standard AD and Optimisers API.","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"# Parameter and State Variables\nps, st = Lux.setup(rng, model) .|> gpu\n\n# Dummy Input\nx = rand(rng, Float32, 128, 2) |> gpu\n\n# Run the model\ny, st = Lux.apply(model, x, ps, st)\n\n# Gradients\ngs = gradient(p -> sum(Lux.apply(model, x, p, st)[1]), ps)[1]\n\n# Optimization\nst_opt = Optimisers.setup(Optimisers.ADAM(0.0001), ps)\nst_opt, ps = Optimisers.update(st_opt, ps, gs)","category":"page"},{"location":"#Citation","page":"Lux: Explicitly Parameterized Neural Networks","title":"Citation","text":"","category":"section"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"If you found this library to be useful in academic work, then please cite:","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"@misc{pal2022lux,\n    author = {Pal, Avik},\n    title = {Lux: Explicit Parameterization of Deep Neural Networks in Julia},\n    year = {2022},\n    publisher = {GitHub},\n    journal = {GitHub repository},\n    howpublished = {\\url{https://github.com/avik-pal/Lux.jl/}}\n}","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"Also consider starring our github repo","category":"page"}]
}
