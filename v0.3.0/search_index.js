var documenterSearchIndex = {"docs":
[{"location":"api/core/","page":"Core","title":"Core","text":"CurrentModule = Lux","category":"page"},{"location":"api/core/#General","page":"Core","title":"General","text":"","category":"section"},{"location":"api/core/","page":"Core","title":"Core","text":"Lux.apply\nLux.setup","category":"page"},{"location":"api/core/#Lux.apply","page":"Core","title":"Lux.apply","text":"apply(model::AbstractExplicitLayer, x, ps::Union{ComponentArray,NamedTuple}, st::NamedTuple)\n\nSimply calls model(x, ps, st)\n\n\n\n\n\n","category":"function"},{"location":"api/core/#Lux.setup","page":"Core","title":"Lux.setup","text":"setup(rng::AbstractRNG, l::AbstractExplicitLayer)\n\nShorthand for getting the parameters and states of the layer l. Is equivalent to (initialparameters(rng, l), initialstates(rng, l)).\n\n\n\n\n\n","category":"function"},{"location":"api/core/#Parameters","page":"Core","title":"Parameters","text":"","category":"section"},{"location":"api/core/","page":"Core","title":"Core","text":"Lux.initialparameters\nLux.parameterlength","category":"page"},{"location":"api/core/#Lux.initialparameters","page":"Core","title":"Lux.initialparameters","text":"initialparameters(rng::AbstractRNG, l)\n\nGenerate the initial parameters of the layer l.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#Lux.parameterlength","page":"Core","title":"Lux.parameterlength","text":"parameterlength(l)\n\nReturn the total number of parameters of the layer l.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#States","page":"Core","title":"States","text":"","category":"section"},{"location":"api/core/","page":"Core","title":"Core","text":"Lux.initialstates\nLux.statelength\nLux.testmode\nLux.trainmode\nLux.update_state","category":"page"},{"location":"api/core/#Lux.initialstates","page":"Core","title":"Lux.initialstates","text":"initialstates(rng::AbstractRNG, l)\n\nGenerate the initial states of the layer l.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#Lux.statelength","page":"Core","title":"Lux.statelength","text":"statelength(l)\n\nReturn the total number of states of the layer l.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#Lux.testmode","page":"Core","title":"Lux.testmode","text":"testmode(st::NamedTuple, mode::Bool=true)\n\nMake all occurances of training in state st !mode\n\n\n\n\n\n","category":"function"},{"location":"api/core/#Lux.trainmode","page":"Core","title":"Lux.trainmode","text":"trainmode(x::Any, mode::Bool=true)\n\nMake all occurances of training in state st mode\n\n\n\n\n\n","category":"function"},{"location":"api/core/#Lux.update_state","page":"Core","title":"Lux.update_state","text":"update_state(st::NamedTuple, key::Symbol, value; layer_check=_default_layer_check(key))\n\nRecursively update all occurances of the key in the state st with the value.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#Index","page":"Core","title":"Index","text":"","category":"section"},{"location":"api/core/","page":"Core","title":"Core","text":"Pages = [\"core.md\"]","category":"page"},{"location":"introduction/ecosystem/#Extended-Deep-Learning-Ecosystem","page":"Ecosystem","title":"Extended Deep Learning Ecosystem","text":"","category":"section"},{"location":"introduction/ecosystem/","page":"Ecosystem","title":"Ecosystem","text":"As you might have noticed we don't do much apart from Neural Networks. All other parts of the DL training/evaluation pipeline should be offloaded to:","category":"page"},{"location":"introduction/ecosystem/","page":"Ecosystem","title":"Ecosystem","text":"Data Manipulation/Loading – Augmentor.jl, DataLoaders.jl, Images.jl, DataAugmentation.jl\nOptimisation – Optimisers.jl, ParameterSchedulers.jl\nAutomatic Differentiation – Zygote.jl\nParameter Manipulation – Functors.jl\nModel Checkpointing – Serialization.jl\nActivation Functions / Common Neural Network Primitives – NNlib.jl\nDistributed DataParallel Training – FluxMPI.jl\nTraining Visualization – Wandb.jl, TensorBoardLogger.jl","category":"page"},{"location":"api/utilities/","page":"Utilities","title":"Utilities","text":"CurrentModule = Lux","category":"page"},{"location":"api/utilities/#Data-Transfer","page":"Utilities","title":"Data Transfer","text":"","category":"section"},{"location":"api/utilities/","page":"Utilities","title":"Utilities","text":"Lux.cpu\nLux.gpu","category":"page"},{"location":"api/utilities/#Lux.cpu","page":"Utilities","title":"Lux.cpu","text":"cpu(x)\n\nTransfer x to CPU\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#Lux.gpu","page":"Utilities","title":"Lux.gpu","text":"gpu(x)\n\nTransfer x to GPU\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#Initialization","page":"Utilities","title":"Initialization","text":"","category":"section"},{"location":"api/utilities/","page":"Utilities","title":"Utilities","text":"Lux.glorot_normal\nLux.glorot_uniform\nLux.ones32\nLux.zeros32","category":"page"},{"location":"api/utilities/#Lux.glorot_normal","page":"Utilities","title":"Lux.glorot_normal","text":"glorot_normal(rng::AbstractRNG, size...; gain = 1)\n\nReturn an Array{Float32} of the given size containing random numbers drawn from a normal distribution with standard deviation gain * sqrt(2 / (fan_in + fan_out)). This method is described in [1] and also known as Xavier initialization.\n\nReferences\n\n[1] Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of training deep feedforward neural networks.\" Proceedings of the thirteenth international conference on artificial intelligence and statistics. 2010.\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#Lux.glorot_uniform","page":"Utilities","title":"Lux.glorot_uniform","text":"glorot_uniform(rng::AbstractRNG, size...; gain = 1)\n\nReturn an Array{Float32} of the given size containing random numbers drawn from a uniform distribution on the interval -x x, where x = gain * sqrt(6 / (fan_in + fan_out)). This method is described in [1] and also known as Xavier initialization.\n\nReferences\n\n[1] Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of training deep feedforward neural networks.\" Proceedings of the thirteenth international conference on artificial intelligence and statistics. 2010.\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#Lux.ones32","page":"Utilities","title":"Lux.ones32","text":"ones32(rng::AbstractRNG, size...) = ones(Float32, size...)\n\nReturn an Array{Float32} of ones of the given size. (rng is ignored)\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#Lux.zeros32","page":"Utilities","title":"Lux.zeros32","text":"zeros32(rng::AbstractRNG, size...) = zeros(Float32, size...)\n\nReturn an Array{Float32} of zeros of the given size. (rng is ignored)\n\n\n\n\n\n","category":"function"},{"location":"api/utilities/#Index","page":"Utilities","title":"Index","text":"","category":"section"},{"location":"api/utilities/","page":"Utilities","title":"Utilities","text":"Pages = [\"utilities.md\"]","category":"page"},{"location":"examples/","page":"Additional Examples","title":"Additional Examples","text":"warn: Warn\nThese were not written in the form of tutorials but standalone scripts/packages for people to use","category":"page"},{"location":"examples/#Packages","page":"Additional Examples","title":"Packages","text":"","category":"section"},{"location":"examples/","page":"Additional Examples","title":"Additional Examples","text":"Deep Equilibrium Models","category":"page"},{"location":"examples/#Scipts","page":"Additional Examples","title":"Scipts","text":"","category":"section"},{"location":"examples/","page":"Additional Examples","title":"Additional Examples","text":"ImageNet Classification using Metalhead.jl Models","category":"page"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"CurrentModule = Lux","category":"page"},{"location":"api/layers/#Containers","page":"Layers","title":"Containers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"BranchLayer\nChain\nPairwiseFusion\nParallel\nSkipConnection","category":"page"},{"location":"api/layers/#Lux.BranchLayer","page":"Layers","title":"Lux.BranchLayer","text":"BranchLayer(layers...)\n\nTakes an input x and passes it through all the layers and returns a tuple of the outputs.\n\nThis is slightly different from Parallel(nothing, layers...)     - If the input is a tuple Parallel will pass each element individually to each layer     - BranchLayer essentially assumes 1 input comes in and is branched out into N outputs\n\nAn easy way to replicate an input to an NTuple is to do\n\nl = BranchLayer(\n        NoOpLayer(),\n        NoOpLayer(),\n        NoOpLayer(),\n    )\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.Chain","page":"Layers","title":"Lux.Chain","text":"Chain(layers...; disable_optimizations::Bool = false)\n\nCollects multiple layers / functions to be called in sequence on a given input.\n\nPerforms a few optimizations to generate reasonable architectures. Can be disabled using keyword argument disable_optimizations.\n\nAll sublayers are recursively optimized.\nIf a function f is passed as a layer and it doesn't take 3 inputs, it is converted to a WrappedFunction(f) which takes only one input.\nIf the layer is a Chain, it is expanded out.\nNoOpLayers are removed.\nIf there is only 1 layer (left after optimizations), then it is returned without the Chain wrapper.\nIf there are no layers (left after optimizations), a NoOpLayer is returned.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.PairwiseFusion","page":"Layers","title":"Lux.PairwiseFusion","text":"PairwiseFusion(connection, layers...)\n\nLayer behaves differently based on input type:\n\nInput x is a tuple of length N then the layers must be a tuple of length N. The computation is as follows\n\ny = x[1]\nfor i in 1:N\n    y = connection(x[i], layers[i](y))\nend\n\nAny other kind of input\n\ny = x\nfor i in 1:N\n    y = connection(x, layers[i](y))\nend\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.Parallel","page":"Layers","title":"Lux.Parallel","text":"Parallel(connection, layers...)\n\nBehaves differently on different input types:\n\nIf x is a Tuple then each element is passed to each layer\nOtherwise, x is directly passed to all layers\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.SkipConnection","page":"Layers","title":"Lux.SkipConnection","text":"SkipConnection(layer, connection)\n\nCreate a skip connection which consists of a layer or Chain of consecutive layers and a shortcut connection linking the block's input to the output through a user-supplied 2-argument callable. The first argument to the callable will be propagated through the given layer while the second is the unchanged, \"skipped\" input.\n\nThe simplest \"ResNet\"-type connection is just SkipConnection(layer, +).\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Convolutional-Layers","page":"Layers","title":"Convolutional Layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Conv","category":"page"},{"location":"api/layers/#Lux.Conv","page":"Layers","title":"Lux.Conv","text":"Conv(filter, in => out, σ = identity; stride = 1, pad = 0, dilation = 1, groups = 1, [bias, initW])\n\nStandard convolutional layer.\n\nArguments\n\nfilter is a tuple of integers specifying the size of the convolutional kernel\nin and out specify the number of input and output channels.\n\nImage data should be stored in WHCN order (width, height, channels, batch). In other words, a 100×100 RGB image would be a 100×100×3×1 array, and a batch of 50 would be a 100×100×3×50 array. This has N = 2 spatial dimensions, and needs a kernel size like (5,5), a 2-tuple of integers. To take convolutions along N feature dimensions, this layer expects as input an array with ndims(x) == N+2, where size(x, N+1) == in is the number of input channels, and size(x, ndims(x)) is (as always) the number of observations in a batch.\n\nfilter should be a tuple of N integers.\nKeywords stride and dilation should each be either single integer, or a tuple with N integers.\nKeyword pad specifies the number of elements added to the borders of the data array. It can be\na single integer for equal padding all around,\na tuple of N integers, to apply the same padding at begin/end of each spatial dimension,\na tuple of 2*N integers, for asymmetric padding, or\nthe singleton SamePad(), to calculate padding such that size(output,d) == size(x,d) / stride (possibly rounded) for each spatial dimension.\nKeyword groups is expected to be an Int. It specifies the number of groups to divide a convolution into.\n\nKeywords to control initialization of the layer:\n\ninitW - Function used to generate initial weights. Defaults to glorot_uniform.\nbias - The initial bias vector is all zero by default. Trainable bias can be disabled entirely by setting this to false.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Dropout-Layers","page":"Layers","title":"Dropout Layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Dropout\nVariationalHiddenDropout","category":"page"},{"location":"api/layers/#Lux.Dropout","page":"Layers","title":"Lux.Dropout","text":"Dropout(p; dims=:)\n\nDropout layer.\n\nArguments\n\nTo apply dropout along certain dimension(s), specify the dims keyword. e.g. Dropout(p; dims = 3) will randomly zero out entire channels on WHCN input (also called 2D dropout).\nEach execution of the Layer increments the seed and returns it wrapped in the state\n\nCall Lux.testmode to switch to test mode.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.VariationalHiddenDropout","page":"Layers","title":"Lux.VariationalHiddenDropout","text":"VariationalHiddenDropout(p; dims=:)\n\nVariationalHiddenDropout layer. The only difference from Dropout is that the mask is retained until Lux.update_state(l, :update_mask, true) is called.\n\nArguments\n\nTo apply dropout along certain dimension(s), specify the dims keyword. e.g. Dropout(p; dims = 3) will randomly zero out entire channels on WHCN input (also called 2D dropout).\nEach execution of the Layer increments the seed and returns it wrapped in the state\n\nCall Lux.testmode to switch to test mode.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Pooling-Layers","page":"Layers","title":"Pooling Layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"AdaptiveMaxPool\nAdaptiveMeanPool\nGlobalMaxPool\nGlobalMeanPool\nMaxPool\nMeanPool","category":"page"},{"location":"api/layers/#Lux.AdaptiveMaxPool","page":"Layers","title":"Lux.AdaptiveMaxPool","text":"AdaptiveMaxPool(out::NTuple)\n\nAdaptive Max Pooling layer. Calculates the necessary window size such that its output has size(y)[1:N] == out. Expects as input an array with ndims(x) == N+2, i.e. channel and batch dimensions, after the N feature dimensions, where N = length(out).\n\nSee also MaxPool, AdaptiveMeanPool.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.AdaptiveMeanPool","page":"Layers","title":"Lux.AdaptiveMeanPool","text":"AdaptiveMeanPool(out::NTuple)\n\nAdaptive Mean Pooling layer. Calculates the necessary window size such that its output has size(y)[1:N] == out. Expects as input an array with ndims(x) == N+2, i.e. channel and batch dimensions, after the N feature dimensions, where N = length(out).\n\nSee also MaxPool, AdaptiveMaxPool.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.GlobalMaxPool","page":"Layers","title":"Lux.GlobalMaxPool","text":"GlobalMaxPool()\n\nGlobal Max Pooling layer. Transforms (w,h,c,b)-shaped input into (1,1,c,b)-shaped output, by performing max pooling on the complete (w,h)-shaped feature maps.\n\nSee also MaxPool, GlobalMeanPool.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.GlobalMeanPool","page":"Layers","title":"Lux.GlobalMeanPool","text":"GlobalMeanPool()\n\nGlobal Mean Pooling layer. Transforms (w,h,c,b)-shaped input into (1,1,c,b)-shaped output, by performing max pooling on the complete (w,h)-shaped feature maps.\n\nSee also MeanPool, GlobalMaxPool.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.MaxPool","page":"Layers","title":"Lux.MaxPool","text":"MaxPool(window::NTuple; pad=0, stride=window)\n\nArguments\n\nMax pooling layer, which replaces all pixels in a block of size window with one.\nExpects as input an array with ndims(x) == N+2, i.e. channel and batch dimensions, after the N feature dimensions, where N = length(window).\nBy default the window size is also the stride in each dimension.\nThe keyword pad accepts the same options as for the Conv layer, including SamePad().\n\nSee also Conv, MeanPool, GlobalMaxPool.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.MeanPool","page":"Layers","title":"Lux.MeanPool","text":"MeanPool(window::NTuple; pad=0, stride=window)\n\nArguments\n\nMean pooling layer, which replaces all pixels in a block of size window with one.\nExpects as input an array with ndims(x) == N+2, i.e. channel and batch dimensions, after the N feature dimensions, where N = length(window).\nBy default the window size is also the stride in each dimension.\nThe keyword pad accepts the same options as for the Conv layer, including SamePad().\n\nSee also Conv, MaxPool, GlobalMeanPool.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Linear-Layers","page":"Layers","title":"Linear Layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Dense\nScale","category":"page"},{"location":"api/layers/#Lux.Dense","page":"Layers","title":"Lux.Dense","text":"Dense(in => out, σ=identity; initW=glorot_uniform, initb=zeros32, bias::Bool=true)\n\nCreate a traditional fully connected layer, whose forward pass is given by: y = σ.(weight * x .+ bias)\n\nThe input x should be a vector of length in, or batch of vectors represented as an in × N matrix, or any array with size(x,1) == in.\nThe output y will be a vector  of length out, or a batch with size(y) == (out, size(x)[2:end]...)\n\nKeyword bias=false will switch off trainable bias for the layer.\n\nThe initialisation of the weight matrix is W = initW(rng, out, in), calling the function given to keyword initW, with default glorot_uniform.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.Scale","page":"Layers","title":"Lux.Scale","text":"Scale(dims, σ=identity; initW=ones32, initb=zeros32, bias::Bool=true)\n\nCreate a Sparsely Connected Layer with a very specific structure (only Diagonal Elements are non-zero). The forward pass is given by: y = σ.(weight .* x .+ bias)\n\nThe input x should be a vector of length dims, or batch of vectors represented as an in × N matrix, or any array with size(x,1) == in.\nThe output y will be a vector  of length dims, or a batch with size(y) == (dims, size(x)[2:end]...)\n\nKeyword bias=false will switch off trainable bias for the layer.\n\nThe initialisation of the weight matrix is W = initW(rng, dims), calling the function given to keyword initW, with default glorot_uniform.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Misc.-Helper-Layers","page":"Layers","title":"Misc. Helper Layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"ActivationFunction\nFlattenLayer\nNoOpLayer\nReshapeLayer\nSelectDim\nWrappedFunction","category":"page"},{"location":"api/layers/#Lux.ActivationFunction","page":"Layers","title":"Lux.ActivationFunction","text":"ActivationFunction(f)\n\nBroadcast f on the input but fallback to CUDNN for Backward Pass\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.FlattenLayer","page":"Layers","title":"Lux.FlattenLayer","text":"FlattenLayer()\n\nFlattens the passed array into a matrix.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.NoOpLayer","page":"Layers","title":"Lux.NoOpLayer","text":"NoOpLayer()\n\nAs the name suggests does nothing but allows pretty printing of layers.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.ReshapeLayer","page":"Layers","title":"Lux.ReshapeLayer","text":"ReshapeLayer(dims)\n\nReshapes the passed array to have a size of (dims..., :)\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.SelectDim","page":"Layers","title":"Lux.SelectDim","text":"SelectDim(dim, i)\n\nSee the documentation for selectdim for more information.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.WrappedFunction","page":"Layers","title":"Lux.WrappedFunction","text":"WrappedFunction(f)\n\nWraps a stateless and parameter less function. Might be used when a function is added to Chain. For example, Chain(x -> relu.(x)) would not work and the right thing to do would be Chain((x, ps, st) -> (relu.(x), st)). An easier thing to do would be Chain(WrappedFunction(Base.Fix1(broadcast, relu)))\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Normalization-Layers","page":"Layers","title":"Normalization Layers","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"BatchNorm\nGroupNorm\nWeightNorm","category":"page"},{"location":"api/layers/#Lux.BatchNorm","page":"Layers","title":"Lux.BatchNorm","text":"BatchNorm(chs::Integer, λ=identity; initβ=zeros32, initγ=ones32,\n          affine = true, track_stats = true, ϵ=1f-5, momentum= 0.1f0)\n\nBatch Normalization layer.\n\nBatchNorm computes the mean and variance for each D_1×...×D_{N-2}×1×D_N input slice and normalises the input accordingly.\n\nArguments\n\nchs should be the size of the channel dimension in your data (see below). Given an array with N dimensions, call the N-1th the channel dimension. For a batch of feature vectors this is just the data dimension, for WHCN images it's the usual channel dimension.\nAfter normalisation, elementwise activation λ is applied.\nIf affine=true, it also applies  a shift and a rescale to the input through to learnable per-channel bias β and scale γ parameters.\nIf track_stats=true, accumulates mean and var statistics in training phase that will be used to renormalize the input in test phase.\n\nUse Lux.testmode during inference.\n\nExamples\n\nm = Chain(\n        Dense(784 => 64),\n        BatchNorm(64, relu),\n        Dense(64 => 10),\n        BatchNorm(10)\n    )\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.GroupNorm","page":"Layers","title":"Lux.GroupNorm","text":"GroupNorm(chs::Integer, groups::Integer, λ=identity; initβ=zeros32, initγ=ones32,\n          affine=true, track_stats=false, ϵ=1f-5, momentum=0.1f0)\n\nGroup Normalization layer.\n\nArguments\n\nchs is the number of channels, the channel dimension of your input. For an array of N dimensions, the N-1th index is the channel dimension.\nG is the number of groups along which the statistics are computed. The number of channels must be an integer multiple of the number of groups.\nAfter normalisation, elementwise activation λ is applied.\nIf affine=true, it also applies  a shift and a rescale to the input through to learnable per-channel bias β and scale γ parameters.\nIf track_stats=true, accumulates mean and var statistics in training phase that will be used to renormalize the input in test phase.\n\nwarn: Warn\nGroupNorm doesn't have CUDNN support. The GPU fallback is not very efficient.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Lux.WeightNorm","page":"Layers","title":"Lux.WeightNorm","text":"WeightNorm(layer::AbstractExplicitLayer, which_params::NTuple{N,Symbol}, dims::Union{Tuple,Nothing}=nothing)\n\nApplies weight normalization to a parameter in the given layer.\n\nw = gfracvv\n\nWeight normalization is a reparameterization that decouples the magnitude of a weight tensor from its direction. This updates the parameters in which_params (e.g. weight) using two parameters: one specifying the magnitude (e.g. weight_g) and one specifying the direction (e.g. weight_v).\n\nBy default, a norm over the entire array is computed. Pass dims to modify the dimension.\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Upsampling","page":"Layers","title":"Upsampling","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Upsample","category":"page"},{"location":"api/layers/#Lux.Upsample","page":"Layers","title":"Lux.Upsample","text":"Upsample(mode = :nearest; [scale, size]) \nUpsample(scale, mode = :nearest)\n\nAn upsampling layer.\n\nArguments\n\nOne of two keywords must be given:\n\nIf scale is a number, this applies to all but the last two dimensions (channel and batch) of the input.  It may also be a tuple, to control dimensions individually.\nAlternatively, keyword size accepts a tuple, to directly specify the leading dimensions of the output.\n\nCurrently supported upsampling modes and corresponding NNlib's methods are:\n\n:nearest -> NNlib.upsample_nearest\n:bilinear -> NNlib.upsample_bilinear\n:trilinear -> NNlib.upsample_trilinear\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#Index","page":"Layers","title":"Index","text":"","category":"section"},{"location":"api/layers/","page":"Layers","title":"Layers","text":"Pages = [\"layers.md\"]","category":"page"},{"location":"#Lux","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux","text":"","category":"section"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"Lux is a julia deep learning framework which decouples models and parameterization using deeply nested named tuples.","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"Functional Layer API – Pure Functions and Deterministic Function Calls.\nNo more implicit parameterization – Zygote.Params. Everything is a NamedTuple.\nCompiler and AD-friendly Neural Networks","category":"page"},{"location":"#Installation","page":"Lux: Explicitly Parameterized Neural Networks","title":"Installation","text":"","category":"section"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"Install julia v1.6 or above.","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"using Pkg\nPkg.add(\"Lux\")","category":"page"},{"location":"#Quick-Example","page":"Lux: Explicitly Parameterized Neural Networks","title":"Quick Example","text":"","category":"section"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"using Lux, Random, Optimisers, Zygote","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"We take randomness very seriously","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"# Seeding\nrng = Random.default_rng()\nRandom.seed!(rng, 0)","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"Build the model","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"# Construct the layer\nmodel = Chain(\n    BatchNorm(128),\n    Dense(128, 256, tanh),\n    BatchNorm(256),\n    Chain(\n        Dense(256, 1, tanh),\n        Dense(1, 10)\n    )\n)","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"Models don't hold parameters and states so initialize them. From there on, we just use our standard AD and Optimisers API.","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"# Parameter and State Variables\nps, st = Lux.setup(rng, model) .|> gpu\n\n# Dummy Input\nx = rand(rng, Float32, 128, 2) |> gpu\n\n# Run the model\ny, st = Lux.apply(model, x, ps, st)\n\n# Gradients\ngs = gradient(p -> sum(Lux.apply(model, x, p, st)[1]), ps)[1]\n\n# Optimization\nst_opt = Optimisers.setup(Optimisers.ADAM(0.0001), ps)\nst_opt, ps = Optimisers.update(st_opt, ps, gs)","category":"page"},{"location":"#Citation","page":"Lux: Explicitly Parameterized Neural Networks","title":"Citation","text":"","category":"section"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"If you found this library to be useful in academic work, then please cite:","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"@misc{pal2022lux,\n    author = {Pal, Avik},\n    title = {Lux: Explicit Parameterization of Deep Neural Networks in Julia},\n    year = {2022},\n    publisher = {GitHub},\n    journal = {GitHub repository},\n    howpublished = {\\url{https://github.com/avik-pal/Lux.jl/}}\n}","category":"page"},{"location":"","page":"Lux: Explicitly Parameterized Neural Networks","title":"Lux: Explicitly Parameterized Neural Networks","text":"Also consider starring our github repo","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"EditURL = \"https://github.com/avik-pal/Lux.jl/blob/main/examples/NeuralODE/main.jl\"","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/#MNIST-Classification-using-Neural-ODEs","page":"NeuralODE","title":"MNIST Classification using Neural ODEs","text":"","category":"section"},{"location":"examples/generated/intermediate/NeuralODE/main/#Package-Imports","page":"NeuralODE","title":"Package Imports","text":"","category":"section"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"using Lux\nusing Pkg #hide\nPkg.activate(joinpath(dirname(pathof(Lux)), \"..\", \"examples\")) #hide\nusing ComponentArrays, CUDA, DiffEqSensitivity, NNlib, Optimisers, OrdinaryDiffEq, Random, Statistics, Zygote\nimport MLDatasets: MNIST\nimport MLDataUtils: convertlabel, LabelEnc\nimport MLUtils: DataLoader, splitobs\nCUDA.allowscalar(false)","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/#Loading-MNIST","page":"NeuralODE","title":"Loading MNIST","text":"","category":"section"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"# Use MLDataUtils LabelEnc for natural onehot conversion\nonehot(labels_raw) = convertlabel(LabelEnc.OneOfK, labels_raw, LabelEnc.NativeLabels(collect(0:9)))\n\nfunction loadmnist(batchsize, train_split)\n    # Load MNIST: Only 1500 for demonstration purposes\n    N = 1500\n    imgs = MNIST.traintensor(1:N)\n    labels_raw = MNIST.trainlabels(1:N)\n\n    # Process images into (H,W,C,BS) batches\n    x_data = Float32.(reshape(imgs, size(imgs, 1), size(imgs, 2), 1, size(imgs, 3)))\n    y_data = onehot(labels_raw)\n    (x_train, y_train), (x_test, y_test) = splitobs((x_data, y_data); at=train_split)\n\n    return (\n        # Use DataLoader to automatically minibatch and shuffle the data\n        DataLoader(collect.((x_train, y_train)); batchsize=batchsize, shuffle=true),\n        # Don't shuffle the test data\n        DataLoader(collect.((x_test, y_test)); batchsize=batchsize, shuffle=false),\n    )\nend","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/#Define-the-Neural-ODE-Layer","page":"NeuralODE","title":"Define the Neural ODE Layer","text":"","category":"section"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"The NeuralODE is a ContainerLayer. It stores a model and the parameters and states of the NeuralODE is same as that of the underlying model.","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"struct NeuralODE{M<:Lux.AbstractExplicitLayer,So,Se,T,K} <: Lux.AbstractExplicitContainerLayer{(:model,)}\n    model::M\n    solver::So\n    sensealg::Se\n    tspan::T\n    kwargs::K\nend\n\nfunction NeuralODE(\n    model::Lux.AbstractExplicitLayer;\n    solver=Tsit5(),\n    sensealg=InterpolatingAdjoint(; autojacvec=ZygoteVJP()),\n    tspan=(0.0f0, 1.0f0),\n    kwargs...,\n)\n    return NeuralODE(model, solver, sensealg, tspan, kwargs)\nend\n\nfunction (n::NeuralODE)(x, ps, st)\n    function dudt(u, p, t)\n        u_, st = n.model(u, p, st)\n        return u_\n    end\n    prob = ODEProblem{false}(ODEFunction{false}(dudt), x, n.tspan, ps)\n    return solve(prob, n.solver; sensealg=n.sensealg, n.kwargs...), st\nend\n\ndiffeqsol_to_array(x::ODESolution{T,N,<:AbstractVector{<:CuArray}}) where {T,N} = dropdims(gpu(x); dims=3)\ndiffeqsol_to_array(x::ODESolution) = dropdims(Array(x); dims=3)","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/#Create-and-Initialize-the-Neural-ODE-Layer","page":"NeuralODE","title":"Create and Initialize the Neural ODE Layer","text":"","category":"section"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"function create_model()\n    # Construct the Neural ODE Model\n    model = Chain(\n        FlattenLayer(),\n        Dense(784, 20, tanh),\n        NeuralODE(\n            Chain(Dense(20, 10, tanh), Dense(10, 10, tanh), Dense(10, 20, tanh));\n            save_everystep=false,\n            reltol=1.0f-3,\n            abstol=1.0f-3,\n            save_start=false,\n        ),\n        diffeqsol_to_array,\n        Dense(20, 10),\n    )\n\n    rng = Random.default_rng()\n    Random.seed!(rng, 0)\n\n    ps, st = Lux.setup(rng, model)\n    ps = ComponentArray(ps) |> gpu\n    st = st |> gpu\n\n    return model, ps, st\nend","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/#Define-Utility-Functions","page":"NeuralODE","title":"Define Utility Functions","text":"","category":"section"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"get_class(x) = argmax.(eachcol(x))\n\nlogitcrossentropy(ŷ, y) = mean(-sum(y .* logsoftmax(ŷ); dims = 1))\n\nfunction loss(x, y, model, ps, st)\n    ŷ, st = model(x, ps, st)\n    return logitcrossentropy(ŷ, y), st\nend\n\nfunction accuracy(model, ps, st, dataloader)\n    total_correct, total = 0, 0\n    st = Lux.testmode(st)\n    iterator = CUDA.functional() ? CuIterator(dataloader) : dataloader\n    for (x, y) in iterator\n        target_class = get_class(cpu(y))\n        predicted_class = get_class(cpu(model(x, ps, st)[1]))\n        total_correct += sum(target_class .== predicted_class)\n        total += length(target_class)\n    end\n    return total_correct / total\nend","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/#Training","page":"NeuralODE","title":"Training","text":"","category":"section"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"function train()\n    model, ps, st = create_model()\n\n    # Training\n    train_dataloader, test_dataloader = loadmnist(128, 0.9)\n\n    opt = Optimisers.ADAM(0.001f0)\n    st_opt = Optimisers.setup(opt, ps)\n\n    ### Warmup the Model\n    img, lab = gpu(train_dataloader.data[1][:, :, :, 1:1]), gpu(train_dataloader.data[2][:, 1:1])\n    loss(img, lab, model, ps, st)\n    (l, _), back = pullback(p -> loss(img, lab, model, p, st), ps)\n    back((one(l), nothing))\n\n    ### Lets train the model\n    nepochs = 9\n    for epoch in 1:nepochs\n        stime = time()\n        iterator = CUDA.functional() ? CuIterator(train_dataloader) : train_dataloader\n        for (x, y) in iterator\n            (l, _), back = pullback(p -> loss(x, y, model, p, st), ps)\n            gs = back((one(l), nothing))[1]\n            st_opt, ps = Optimisers.update(st_opt, ps, gs)\n        end\n        ttime = time() - stime\n\n        println(\n            \"[$epoch/$nepochs] \\t Time $(round(ttime; digits=2))s \\t Training Accuracy: \" *\n            \"$(round(accuracy(model, ps, st, train_dataloader) * 100; digits=2))% \\t \" *\n            \"Test Accuracy: $(round(accuracy(model, ps, st, test_dataloader) * 100; digits=2))%\"\n        )\n    end\nend\n\ntrain()","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"","category":"page"},{"location":"examples/generated/intermediate/NeuralODE/main/","page":"NeuralODE","title":"NeuralODE","text":"This page was generated using Literate.jl.","category":"page"},{"location":"introduction/overview/#Why-we-wrote-Lux?","page":"All about Lux","title":"Why we wrote Lux?","text":"","category":"section"},{"location":"introduction/overview/","page":"All about Lux","title":"All about Lux","text":"Julia already has quite a few well established Neural Network Frameworks – Flux & KNet. However, certain design elements – Coupled Model and Parameters & Internal Mutations – associated with these frameworks make them less compiler and user friendly. Making changes to address these problems in the respective frameworks would be too disruptive for users. Here comes in Lux a neural network framework built completely using pure functions to make it both compiler and autodiff friendly.","category":"page"},{"location":"introduction/overview/#Design-Principles","page":"All about Lux","title":"Design Principles","text":"","category":"section"},{"location":"introduction/overview/","page":"All about Lux","title":"All about Lux","text":"Layers must be immutable – cannot store any parameter/state but rather store the information to construct them\nLayers are pure functions\nLayers return a Tuple containing the result and the updated state\nGiven same inputs the outputs must be same – yes this must hold true even for stochastic functions. Randomness must be controlled using rngs passed in the state.\nEasily extendible","category":"page"},{"location":"introduction/overview/#AbstractExplicitLayer-API","page":"All about Lux","title":"AbstractExplicitLayer API","text":"","category":"section"},{"location":"introduction/overview/","page":"All about Lux","title":"All about Lux","text":"We provide 2 abstract layers:","category":"page"},{"location":"introduction/overview/","page":"All about Lux","title":"All about Lux","text":"AbstractExplicitLayer: Useful for Base Layers and needs to define the following functions\ninitialparameters(rng::AbstractRNG, layer::CustomAbstractExplicitLayer) – This returns a ComponentArray/NamedTuple containing the trainable parameters for the layer.\ninitialstates(rng::AbstractRNG, layer::CustomAbstractExplicitLayer) – This returns a NamedTuple containing the current state for the layer. For most layers this is typically empty. Layers that would potentially contain this include BatchNorm, LSTM, GRU etc.\nparameterlength(layer::CustomAbstractExplicitLayer) – These can be automatically calculated, but it is recommended that the user defines these.\nstatelength(layer::CustomAbstractExplicitLayer) – These can be automatically calculated, but it is recommended that the user defines these.\nAbstractExplicitContainerLayer: Used when the layer is storing other AbstractExplicitLayers or AbstractExplicitContainerLayers. This allows good defaults of the dispatches for functions mentioned in the previous point.","category":"page"},{"location":"introduction/overview/","page":"All about Lux","title":"All about Lux","text":"note: Note\nWe recommend users to subtype their custom layers using AbstractExplicitLayer or AbstractExplicitContainerLayer. However, this is not mandatory.","category":"page"},{"location":"introduction/overview/#Why-use-Lux-over-Flux?","page":"All about Lux","title":"Why use Lux over Flux?","text":"","category":"section"},{"location":"introduction/overview/","page":"All about Lux","title":"All about Lux","text":"Large Neural Networks\nFor small neural networks we recommend SimpleChains.jl.\nFor SciML Applications (Neural ODEs, Deep Equilibrium Models) solvers typically expect a monolithic parameter vector. Flux enables this via its destructure mechanism, however, it often leads to weird bugs. Lux forces users to make an explicit distinction between state variables and parameter variables to avoid these issues.\nComes battery-included for distributed training using FluxMPI.jl\nSensible display of Custom Layers – Ever wanted to see Pytorch like Network printouts or wondered how to extend the pretty printing of Flux's layers. Lux handles all of that by default.\nLess Bug-ridden Code\nNo arbitrary internal mutations – all layers are implemented as pure functions.\nAll layers are deterministic given the parameter and state – if the layer is supposed to be stochastic (say Dropout), the state must contain a seed which is then updated after the function call.\nEasy Parameter Manipulation – Wondering why Flux doesn't have WeightNorm, SpectralNorm, etc. The implicit parameter handling makes it extremely hard to pass parameters around without mutations which AD systems don't like. With Lux implementing them is outright simple.","category":"page"}]
}
